{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BitViT - Example Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training script\n",
    "%run -i train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1000\n",
    "config = {\n",
    "    \"project\": \"distill-vit-pretrain\",\n",
    "    \"experiment\": \"bit-vit\",\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 256,\n",
    "    \"accum_steps\": 4, # gradient accumulation steps\n",
    "    \"warmup\": 5, # in epochs\n",
    "    \"distill\": {\n",
    "        \"enabled\": True,\n",
    "        \"args\": {\n",
    "            \"teacher\": efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1),\n",
    "            \"hard\": True,  # use hard or soft labels\n",
    "            \"alpha\": 0.5,  # trade-off between main loss and distillation loss\n",
    "            \"temperature\": 1.0,  # only used for soft distillation\n",
    "        },\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"model\": DistillableBitViT,\n",
    "        \"args\": { # based on DeiT-Small\n",
    "            \"image_size\": 224,\n",
    "            \"patch_size\": 16,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"dim\": 384,\n",
    "            \"depth\": 12,\n",
    "            \"heads\": 6,\n",
    "            \"mlp_dim\": 1536,\n",
    "            \"spt\": True, # from vits for small datasets\n",
    "            \"sincos2d\": True, # from SimpleViT\n",
    "        },\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": torch.optim.AdamW,\n",
    "        \"args\": {  # based on SimpleViT\n",
    "            \"lr\": 1e-3,\n",
    "            \"weight_decay\": 0.05,\n",
    "        },\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"type\": torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "        \"args\": {\n",
    "            \"T_max\": 90,\n",
    "        },\n",
    "    },\n",
    "    \"criterion\": { # disabled for distillation\n",
    "        \"type\": nn.CrossEntropyLoss,\n",
    "        \"args\": {},\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"path\": f\"{os.environ['TMPDIR']}/datasets/imagenet-1k-rgb-256\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"preprocess\": {\n",
    "            \"train\": transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandAugment(2, 10),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            \"validation\": transforms.Compose(\n",
    "                [\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        },\n",
    "        \"cutmix_or_mixup\": {\n",
    "            \"enabled\": True,\n",
    "            \"mixup\": 0.2, # alpha\n",
    "            \"cutmix\": 1.0, # alpha \n",
    "            \"p\": [0.0, 1.0], # only mixup\n",
    "        },\n",
    "        \"loader\": {\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 16,\n",
    "            \"prefetch_factor\": 4,\n",
    "            \"pin_memory\": True,\n",
    "            \"drop_last\": True,\n",
    "            \"persistent_workers\": True,\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"enabled\": True,\n",
    "        \"log_interval\": 100,\n",
    "    },\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
